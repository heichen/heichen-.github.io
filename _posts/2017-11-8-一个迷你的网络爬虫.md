---
layout: post
title:  "一个迷你的网络爬虫"
categories: java
tags:  java
author: DarkChen
---

* content
{:toc}

网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。今天利用午休写了一个迷你的小爬虫。抓取搜狐新闻。

![](http://img.blog.csdn.net/20171229094012759?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGVpX2NoZW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)




## 代码

首先做一个小蜘蛛

### spider.java
```java
package com.FFMS.webSpider;

import java.io.BufferedReader;
import java.io.InputStreamReader;
import java.net.URL;
import java.net.URLConnection;
import java.util.ArrayList;
import java.util.regex.Pattern;

public class spider {
    public static String sendGet(String url){
        BufferedReader reader=null;

        String result=null;

        try {
            URL realUrl=new URL(url);
            URLConnection connection=realUrl.openConnection();
            reader=new BufferedReader(new InputStreamReader(connection.getInputStream(),"utf-8"));
            String line;

            while((line=reader.readLine())!=null){
                result+=line;
            }
            return result;
        }catch (Exception e){
            throw new RuntimeException("get请求的时候发生异常！");
        }finally {
            try {
                if (reader!=null) reader.close();
            }catch (Exception e){
                e.printStackTrace();
            }
        }
    }

    public static ArrayList<zhihu> regexString(String targetStr){

        ArrayList<zhihu> lists= new ArrayList<zhihu>();

        //Pattern titlePattern=Pattern.compile();

        return lists;
    }
}

```
测试类

### test.java
```java
package com.FFMS.webSpider;

import java.util.regex.Matcher;
import java.util.regex.Pattern;

public class test {


    public static String regexString(String targetStr, String patternStr)
    {
        // 定义一个样式模板，此中使用正则表达式，括号中是要抓的内容
        // 相当于埋好了陷阱匹配的地方就会掉下去
        Pattern pattern=Pattern.compile(patternStr);

        // 定义一个matcher用来做匹配
        Matcher matcher=pattern.matcher(targetStr);

        if (matcher.find())
        {
            return matcher.group(1);
        }

        return "没有找到相匹配的字符";
    }

//抓新闻
    public static void main(String[] args){
        String url="http://news.sohu.com/";
        String result=spider.sendGet(url);
        //String title=regexString(result,"linkto.+?>(.+?)<");
        String title=regexString(result,"data-param.+?title=\"(.+?)\"");
        String text=regexString(result,"data-param.+?href=\"(.+?)\"");
        String img=regexString(result,"data-param.+?src=\"(.+?)\"");

        System.out.println("标题："+title);
        System.out.println("内容："+text);
        System.out.println("图片："+img);

    }
}


``` 
	
## 成功

![](http://img.blog.csdn.net/20171229094012759?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGVpX2NoZW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

